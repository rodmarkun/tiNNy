{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tinny\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = np.array(pd.read_csv('./data/classification/train.csv')).T\n",
    "data_test = np.array(pd.read_csv('./data/classification/test.csv')).T\n",
    "\n",
    "m, n = data_train.shape\n",
    "\n",
    "X_train = data_train[1:n]\n",
    "y_train = data_train[0]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train.T, y_train, train_size=35000, random_state=42)\n",
    "\n",
    "X_train = X_train.T / 255.0\n",
    "X_test = X_test.T / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 1 0 8 0]\n"
     ]
    }
   ],
   "source": [
    "print(y_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n",
      "Loss: 0.8355691488908573\n",
      "Accuracy: 0.09831428571428572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10\n",
      "Loss: 4.103125776530838\n",
      "Accuracy: 0.3031714285714286\n",
      "Iteration 20\n",
      "Loss: 3.4216616087823013\n",
      "Accuracy: 0.495\n",
      "Iteration 30\n",
      "Loss: 2.855612598558572\n",
      "Accuracy: 0.6291428571428571\n",
      "Iteration 40\n",
      "Loss: 2.4574065952731887\n",
      "Accuracy: 0.6381714285714286\n",
      "Iteration 50\n",
      "Loss: 2.9630703793386983\n",
      "Accuracy: 0.7057428571428571\n",
      "Iteration 60\n",
      "Loss: 2.7609542733164694\n",
      "Accuracy: 0.7396857142857143\n",
      "Iteration 70\n",
      "Loss: 2.582316038521627\n",
      "Accuracy: 0.7667428571428572\n",
      "Iteration 80\n",
      "Loss: 2.4909552000694726\n",
      "Accuracy: 0.7846857142857143\n",
      "Iteration 90\n",
      "Loss: 2.428093846235178\n",
      "Accuracy: 0.7995428571428571\n",
      "Iteration 100\n",
      "Loss: 2.376807726720783\n",
      "Accuracy: 0.8117714285714286\n",
      "Iteration 110\n",
      "Loss: 2.3418453191152606\n",
      "Accuracy: 0.8218857142857143\n",
      "Iteration 120\n",
      "Loss: 2.3342339748339853\n",
      "Accuracy: 0.8297142857142857\n",
      "Iteration 130\n",
      "Loss: 2.3166939936898086\n",
      "Accuracy: 0.8363428571428572\n",
      "Iteration 140\n",
      "Loss: 2.3150118742506773\n",
      "Accuracy: 0.8406285714285714\n",
      "Iteration 150\n",
      "Loss: 2.3119039495687064\n",
      "Accuracy: 0.8456571428571429\n",
      "Iteration 160\n",
      "Loss: 2.3101027389275868\n",
      "Accuracy: 0.8514285714285714\n",
      "Iteration 170\n",
      "Loss: 2.3002728818723996\n",
      "Accuracy: 0.8555714285714285\n",
      "Iteration 180\n",
      "Loss: 2.288131832994357\n",
      "Accuracy: 0.8591714285714286\n",
      "Iteration 190\n",
      "Loss: 2.275164470314358\n",
      "Accuracy: 0.8628285714285714\n",
      "Iteration 200\n",
      "Loss: 2.268827632073869\n",
      "Accuracy: 0.8660285714285715\n",
      "Iteration 210\n",
      "Loss: 2.261969215608309\n",
      "Accuracy: 0.8681142857142857\n",
      "Iteration 220\n",
      "Loss: 2.2531373910900343\n",
      "Accuracy: 0.8704571428571428\n",
      "Iteration 230\n",
      "Loss: 2.2486808835017644\n",
      "Accuracy: 0.8726\n",
      "Iteration 240\n",
      "Loss: 2.240566920129836\n",
      "Accuracy: 0.875\n",
      "Iteration 250\n",
      "Loss: 2.2357718408468035\n",
      "Accuracy: 0.8771428571428571\n",
      "Iteration 260\n",
      "Loss: 2.2311729559924935\n",
      "Accuracy: 0.8787714285714285\n",
      "Iteration 270\n",
      "Loss: 2.2302957872641525\n",
      "Accuracy: 0.8806571428571428\n",
      "Iteration 280\n",
      "Loss: 2.2305916297088326\n",
      "Accuracy: 0.8825428571428572\n",
      "Iteration 290\n",
      "Loss: 2.2302506885133853\n",
      "Accuracy: 0.8842285714285715\n",
      "Iteration 300\n",
      "Loss: 2.2260696382273113\n",
      "Accuracy: 0.8856\n",
      "Iteration 310\n",
      "Loss: 2.223993821660406\n",
      "Accuracy: 0.8867142857142857\n",
      "Iteration 320\n",
      "Loss: 2.221947333138145\n",
      "Accuracy: 0.8878571428571429\n",
      "Iteration 330\n",
      "Loss: 2.2247613056915267\n",
      "Accuracy: 0.8888857142857143\n",
      "Iteration 340\n",
      "Loss: 2.2247063434340255\n",
      "Accuracy: 0.8897428571428572\n",
      "Loss in test: 2.1398414384846522\n",
      "Accuracy in test: 0.8887142857142857\n"
     ]
    }
   ],
   "source": [
    "l1 = tinny.DenseLayer(784, 10, \"ReLU\")\n",
    "l2 = tinny.OutputLayer(10, 10, \"softmax\")\n",
    "nn = tinny.TiNNyNetwork(problem_type=\"classification\", loss_function=\"crossentropy\", layers=[l1, l2])\n",
    "\n",
    "nn.train(X_train, y_train, iterations=350, learning_rate=0.01)\n",
    "nn.test(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
